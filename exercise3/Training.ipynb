{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import pickle\n",
    "\n",
    "from utils import buildNetwork, load_cifar,download_cifar\n",
    "\n",
    "# URL for the data-set on the internet.\n",
    "data_path = \"data/CIFAR-10/\"\n",
    "data_url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's start a Session\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download CIFAR-10 (only needs to be run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "download_cifar(data_path, data_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading CIFAR-10 into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_samples, train_labels, val_samples, val_labels = load_cifar(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Use matplotlib to plot 5 random *training* samples and print the corresponding class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_to_name = ['airplane', 'automobile', 'bird', 'cat', 'deer' , 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# TODO plot 5 training samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Tensorflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HEIGHT = 32\n",
    "WIDTH = 32\n",
    "CHANNELS = 3\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# You can also modify these hyper-parameters (batch_size, epochs)\n",
    "# e.g. Add more epochs, if not converged. Reduce batch_size if too big for your GPU memory\n",
    "batch_size = 50  \n",
    "num_train_epochs = 10\n",
    "steps_per_epoch = train_samples.shape[0] / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO define placeholders for the inputs and their labels (hint: what is their type, shape?)\n",
    "\n",
    "inputs = \n",
    "labels = \n",
    "\n",
    "logits = buildNetwork(inputs, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Build the Loss. Add weight regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO add an appropriate cross entropy loss function\n",
    "\n",
    "\n",
    "# TODO use reduce_mean to combine the single loss values from all the different input samples\n",
    "\n",
    "\n",
    "# TODO add L2 regularization\n",
    "# hint: use tf.trainable_variables() and tf.nn.l2_loss(var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute accuracy as an evaluation metric\n",
    "predictions = tf.to_int32(tf.argmax(logits, axis=1))\n",
    "correct_mask = tf.to_float(tf.equal(predictions, labels))\n",
    "accuracy = tf.reduce_mean(correct_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Define Learning Rate, Optimizer and Training Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO define the learning rate\n",
    "\n",
    "# TODO define the optimizer (experiment with different options)\n",
    "\n",
    "# TODO build the corresponding training operation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define summary operations. Note, that the names may vary depending on how you defined variables!\n",
    "\n",
    "train_summaries = [\n",
    "  tf.summary.scalar('train_loss', loss),\n",
    "  tf.summary.scalar('train_accuracy', accuracy)\n",
    "]\n",
    "train_summary_op = tf.summary.merge(train_summaries)\n",
    "\n",
    "val_accuracy = tf.placeholder(tf.float32)\n",
    "val_summary_op = tf.summary.scalar('val_accuracy', val_accuracy)\n",
    "\n",
    "# Define a single summary writer, which will take care of writing\n",
    "# our summary representations to disk.\n",
    "writer = tf.summary.FileWriter('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Initialize the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO use the variables initializer to build the operation and run it in the current session (named sess)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Task: Train your network. Display the progress. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# indicators on how often to create a summary\n",
    "num_steps_per_train_summary = 25  \n",
    "\n",
    "# TODO run num_train_steps iterations on the training samples each of batchsize 50\n",
    "for epoch in range(num_train_epochs):\n",
    "    \n",
    "    # TODO randomly shuffle training samples\n",
    "    \n",
    "    for iter in range(steps_per_epoch):\n",
    "    \n",
    "        # TODO read the batch and execute one iteration of the graph \n",
    "    \n",
    "    \n",
    "        # TODO every num_steps_per_train_summary iterations: \n",
    "        #     save the current training status (loss and accuracy) to tensorboard\n",
    "    \n",
    "        \n",
    "    # TODO every epoch: \n",
    "    #     save the current validation accuracy to tensorboard\n",
    "    # Note: we are interested in the accuracy over the *entire* validation set, not just the current batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Save the trained model into checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO use tf.train.Saver to save the trained model as checkpoints/model.ckpt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Exercise: Use different methods to further improve your accuracy. \n",
    "### e.g. De-mean input, use data Augmentation (flip image, rotate image, add noise), add dropout ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hint: tf.nn.dropout, tf.image.flip_left_right, .... \n",
    "# Note that this should only be applied during training and not during testing!! \n",
    "# Hint: Use an extra tf.placeholder to indicate if training.\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
