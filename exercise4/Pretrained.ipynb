{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Overview\n",
    "\n",
    "TF-Slim is a lightweight library for defining, training and evaluating complex models in TensorFlow. Components of tf-slim can be freely mixed with native tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Visit https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim to get a quick introduction to the library.\n",
    "\n",
    "Visit https://www.tensorflow.org/api_docs/python/tf/contrib/layers to get an overview of some of the layers we'll be using in this tutorial. For example, take a look at `fully_connected` and `conv2d`, which *takes care of creating trainable weights for you.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Toy Example for Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import matplot for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "#to see the plots inside of the notebook\n",
    "%matplotlib inline\n",
    "# import tensorflow and required layers\n",
    "# note that tensorflow.contrib.layers was previously migrated from TF Slim.\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import conv2d, fully_connected\n",
    "\n",
    "# create a session\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create toy input 32x32 (white square in black background)\n",
    "inputs = np.pad(np.ones([16, 16]), pad_width=[[8, 8], [8, 8]], mode='constant')\n",
    "inputs = inputs.reshape([1, 32, 32, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Let's get used to Slim with a simple toy example using one convolution\n",
    "# and multiple activation functions.\n",
    "\n",
    "# Specify input as a placeholder with corresponding shape\n",
    "# batch_size x width x height x channels\n",
    "input_layer = tf.placeholder(tf.float32, shape=(1, 32, 32, 1))\n",
    "\n",
    "# Convolution with a 3x3 kernel having 16 output feature maps, using ReLUs,\n",
    "# and using padding='SAME' to retain the same spatial dimensions (width, height)\n",
    "# by first padding the input with zeros.\n",
    "conv_layer = conv2d(inputs=input_layer, num_outputs=16, kernel_size=[3,3],\n",
    "                    activation_fn=tf.nn.relu, stride=1,  padding='SAME')\n",
    "\n",
    "# Next, we'll apply a fully-connected layer, which will be applied as a\n",
    "# matrix multiplication. To do this, we need to flatten each input image\n",
    "# (which here is a single image). Notice that Slim layers are simply\n",
    "# Tensors, which are directly compatible with TensorFlow.\n",
    "conv_layer_flat = tf.reshape(conv_layer, [1, -1])\n",
    "\n",
    "# Create a fully connected layers with 10 hidden neurons. Here we're still using\n",
    "# ReLU activations; we don't actually need to specify it explicitly because\n",
    "# it's the default.\n",
    "fc_layer = fully_connected(inputs=conv_layer_flat, num_outputs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Initialize all the variables which we created\n",
    "init_op = tf.global_variables_initializer()\n",
    "session.run(init_op)\n",
    "\n",
    "# Run the network and obtain output from both layers.\n",
    "conv_out, fully_out = session.run([conv_layer, fc_layer], feed_dict={input_layer: inputs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Now let's visualize the input and the 10 feature maps of the convolution layer.\n",
    "plt.imshow(inputs[0,:,:,0], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# Pluck out the 0-th image and then all 16 feature maps, and visualize\n",
    "# the result.\n",
    "for i in range(16):\n",
    "    feature_map = conv_out[0, :, :, i]\n",
    "    plt.imshow(feature_map, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fc_features = fully_out[0, :]\n",
    "plt.plot(fc_features, 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Exercise\n",
    "## Working with Pretrained Slim Models\n",
    "\n",
    "Here we load a VGG16 model which has already been trained on ImageNet. ImageNet is a large dataset with approximately 1,000,000 images and 1,000 classes, e.g. aeroplanes, cars, types of dogs, etc.\n",
    "\n",
    "In this exercise you will have to use a pretrained vgg network and apply it to three given images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We begin with some preprocessing code to load the ImageNet class names.\n",
    "# This code is from https://github.com/tensorflow/models/blob/master/slim/datasets/imagenet.py\n",
    "\n",
    "filename = \"data/IMAGENET/predictions_to_labels.txt\"\n",
    "synset_list = [s.strip() for s in open(filename).readlines()]\n",
    "num_synsets_in_ilsvrc = len(synset_list)\n",
    "assert num_synsets_in_ilsvrc == 1000\n",
    "\n",
    "filename = \"data/IMAGENET/labels_to_human.txt\"\n",
    "synset_to_human_list = open(filename).readlines()\n",
    "num_synsets_in_all_imagenet = len(synset_to_human_list)\n",
    "assert num_synsets_in_all_imagenet == 21842\n",
    "\n",
    "synset_to_human = {}\n",
    "for s in synset_to_human_list:\n",
    "    parts = s.strip().split('\\t')\n",
    "    assert len(parts) == 2\n",
    "    synset = parts[0]\n",
    "    human = parts[1]\n",
    "    synset_to_human[synset] = human\n",
    "\n",
    "label_index = 0\n",
    "labels_to_names = dict()\n",
    "\n",
    "for synset in synset_list:\n",
    "    name = synset_to_human[synset]\n",
    "    labels_to_names[label_index] = name\n",
    "    label_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import conv2d, fully_connected, max_pool2d, repeat\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "# Network definition copied from https://github.com/tensorflow/models/blob/master/slim/nets/vgg.py\n",
    "def vgg_16(inputs, num_classes=1000, scope='vgg_16'):\n",
    "    \n",
    "    with tf.variable_scope(scope, 'vgg_16', [inputs]) as sc:\n",
    "        \n",
    "        with slim.arg_scope([conv2d, fully_connected, max_pool2d]):\n",
    "            net = repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')\n",
    "            net = max_pool2d(net, [2, 2], scope='pool1')\n",
    "            net = repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')\n",
    "            net = max_pool2d(net, [2, 2], scope='pool2')\n",
    "            net = repeat(net, 3, slim.conv2d, 256, [3, 3], scope='conv3')\n",
    "            net = max_pool2d(net, [2, 2], scope='pool3')\n",
    "            net = repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv4')\n",
    "            net = max_pool2d(net, [2, 2], scope='pool4')\n",
    "            net = repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv5')\n",
    "            net = max_pool2d(net, [2, 2], scope='pool5')\n",
    "            # Use conv2d instead of fully_connected layers.\n",
    "            net = conv2d(net, 4096, [7, 7], padding='VALID', scope='fc6')\n",
    "            net = conv2d(net, 4096, [1, 1], scope='fc7')\n",
    "            net = conv2d(net, num_classes, [1, 1], activation_fn=None, normalizer_fn=None, scope='fc8')\n",
    "            \n",
    "            return net    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create the placeholder for the inputs. Note that the input shape for vgg is 224 x 224 x 3 (in classification mode)\n",
    "inputs = \n",
    "\n",
    "# Build the network (It requires inputs and number of output classes) \n",
    "\n",
    "# Transform logits to probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load the three given images which can be found in the images directory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create the initialization function for the variables of the network\n",
    "\n",
    "# Define an operator to load model variables from a checkpoint using Slim.\n",
    "# The checkpoint can be found at https://github.com/tensorflow/models/tree/master/slim\n",
    "\n",
    "# Start a tensorflow session and run the aforementioned operators\n",
    "\n",
    "# Predict the classes for the given images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot the images together with the top-5 classes plus the associated probabilities for these classes\n",
    "# (hint: sort)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
