{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import matplot for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "#to see the plots inside of the notebook\n",
    "%matplotlib inline\n",
    "# import tensorflow and required layers\n",
    "# note that tensorflow.contrib.layers was previously migrated from TF Slim.\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import conv2d, fully_connected, max_pool2d, repeat\n",
    "from scipy import misc\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "\n",
    "# create a session\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We begin with some preprocessing code to load the ImageNet class names.\n",
    "# This code is from https://github.com/tensorflow/models/blob/master/slim/datasets/imagenet.py\n",
    "\n",
    "filename = \"data/IMAGENET/predictions_to_labels.txt\"\n",
    "synset_list = [s.strip() for s in open(filename).readlines()]\n",
    "num_synsets_in_ilsvrc = len(synset_list)\n",
    "assert num_synsets_in_ilsvrc == 1000\n",
    "\n",
    "filename = \"data/IMAGENET/labels_to_human.txt\"\n",
    "synset_to_human_list = open(filename).readlines()\n",
    "num_synsets_in_all_imagenet = len(synset_to_human_list)\n",
    "assert num_synsets_in_all_imagenet == 21842\n",
    "\n",
    "synset_to_human = {}\n",
    "for s in synset_to_human_list:\n",
    "    parts = s.strip().split('\\t')\n",
    "    assert len(parts) == 2\n",
    "    synset = parts[0]\n",
    "    human = parts[1]\n",
    "    synset_to_human[synset] = human\n",
    "\n",
    "label_index = 0\n",
    "labels_to_names = dict()\n",
    "\n",
    "for synset in synset_list:\n",
    "    name = synset_to_human[synset]\n",
    "    labels_to_names[label_index] = name\n",
    "    label_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Network definition copied from https://github.com/tensorflow/models/blob/master/slim/nets/vgg.py\n",
    "def vgg_16(inputs, num_classes=1000, scope='vgg_16'):\n",
    "    \n",
    "    with tf.variable_scope(scope, 'vgg_16', [inputs]) as sc:\n",
    "        \n",
    "        with slim.arg_scope([conv2d, fully_connected, max_pool2d]):\n",
    "            net = repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')\n",
    "            net = max_pool2d(net, [2, 2], scope='pool1')\n",
    "            net = repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')\n",
    "            net = max_pool2d(net, [2, 2], scope='pool2')\n",
    "            net = repeat(net, 3, slim.conv2d, 256, [3, 3], scope='conv3')\n",
    "            net = max_pool2d(net, [2, 2], scope='pool3')\n",
    "            net = repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv4')\n",
    "            net = max_pool2d(net, [2, 2], scope='pool4')\n",
    "            net = repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv5')\n",
    "            #print(dir(net))\n",
    "            #net = max_pool2d(net, [2, 2], scope='pool5')\n",
    "            # Use conv2d instead of fully_connected layers.\n",
    "            #net = conv2d(net, 4096, [7, 7], padding='VALID', scope='fc6')\n",
    "            #net = conv2d(net, 4096, [1, 1], scope='fc7')\n",
    "            #net = conv2d(net, num_classes, [1, 1], activation_fn=None, normalizer_fn=None, scope='fc8')\n",
    "            \n",
    "            return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the placeholder for the inputs. Note that the input shape for vgg is 224 x 224 x 3 (in classification mode)\n",
    "inputs = tf.placeholder(dtype=tf.float32,shape=(1,224,224,3))\n",
    "\n",
    "\n",
    "# Build the network (It requires inputs and number of output classes) \n",
    "vgg = vgg_16(inputs)\n",
    "\n",
    "\n",
    "# Transform logits to probabilities\n",
    "#probs = tf.nn.softmax(vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load 3 images\n",
    "imgsDir = 'images/'\n",
    "imgsType='.jpg'\n",
    "imgsNames = ['fly','car','jet']\n",
    "imgs = [misc.imresize(misc.imread(imgsDir+imgName+imgsType),size=[224,224]).reshape([1,224,224,3]) for imgName in imgsNames ]\n",
    "# imgFly = misc.imread('images/fly.jpg')\n",
    "# imgFly = misc.imresize(imgFly,size=[224,224])\n",
    "# imgCar = misc.imread('images/car.jpg')\n",
    "# imgCar = misc.imresize(imgCar,size=[224,224])\n",
    "# imgJet = misc.imread('images/jet.jpg')\n",
    "# imgJet = misc.imresize(imgJet,size=[224,224])\n",
    "\n",
    "#print(img.shape)    # (32, 32, 3)\n",
    "\n",
    "#img_tf = tf.Variable(img)\n",
    "#print(img_tf.get_shape().as_list())  # [32, 32, 3]\n",
    "\n",
    "# plt.imshow(imgFly)\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(imgCar)\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(imgJet)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/vgg_16.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Create the initialization function for the variables of the network\n",
    "init_op = tf.global_variables_initializer()\n",
    "session.run(init_op)\n",
    "\n",
    "# Define an operator to load model variables from a checkpoint using Slim.\n",
    "# The checkpoint can be found at https://github.com/tensorflow/models/tree/master/slim\n",
    "\n",
    "# TODO restore the saved checkpoints ./checkpoints/model.ckpt\n",
    "\n",
    "# Assuming than 'conv1/weights' should be restored from 'vgg16/conv1/weights'\n",
    "\n",
    "from tensorflow.python.tools.inspect_checkpoint import print_tensors_in_checkpoint_file\n",
    "#print_tensors_in_checkpoint_file(file_name='checkpoints/vgg_16.ckpt', tensor_name='', all_tensors='')\n",
    "\n",
    "#tvars =tf.trainable_variables()\n",
    "#print(tvars)\n",
    "\n",
    "def name_in_checkpoint(var):\n",
    "  if var.name.startswith('vgg'):\n",
    "    return var.name.split(':')[0]\n",
    "  return 'vgg_16/' + var.name.split(':')[0]\n",
    "\n",
    "\n",
    "variables_to_restore = slim.get_model_variables()\n",
    "variables_to_restore = {name_in_checkpoint(var):var for var in variables_to_restore}\n",
    "\n",
    "cleaned = dict()\n",
    "\n",
    "for var in slim.get_model_variables():\n",
    " \n",
    "  if var.op.name.startswith('fully_connected') or var.op.name.startswith('Conv') :\n",
    "    continue\n",
    "  cleaned[name_in_checkpoint(var)]=var\n",
    "\n",
    "#print(cleaned)\n",
    "\n",
    "restorer = tf.train.Saver(cleaned)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  # Restore variables from disk.\n",
    "  restorer.restore(session, \"checkpoints/vgg_16.ckpt\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 14)\n"
     ]
    }
   ],
   "source": [
    "# Start a tensorflow session and run the aforementioned operators\n",
    "#imgJetReshaped = imgJet.reshape([1,224,224,3])\n",
    "\n",
    "# #Predict the classes for the given images\n",
    "#for img in imgs:\n",
    "img=imgs[0]\n",
    "probsOut = session.run([vgg],feed_dict={inputs:img})\n",
    "print(probsOut[0][0,:,:,0].shape)\n",
    "    #for idx in ((probsOut[0][0,0,0,:]).argsort()[-5:][::-1]):\n",
    "    #    print(labels_to_names[idx]+': '+str(probsOut[0][0,0,0,:][idx]))\n",
    "    #plt.imshow(img[0,:,:,:])\n",
    "    #plt.show()\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import matplot for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "#to see the plots inside of the notebook\n",
    "%matplotlib inline\n",
    "# import tensorflow and required layers\n",
    "# note that tensorflow.contrib.layers was previously migrated from TF Slim.\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import conv2d, fully_connected, max_pool2d, repeat\n",
    "from scipy import misc\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "\n",
    "# create a session\n",
    "session = tf.Session()\n",
    "\n",
    "\n",
    "# Load 3 images\n",
    "imgsDir = 'images/'\n",
    "imgsType='.jpg'\n",
    "imgsNames = ['fly','car','jet']\n",
    "imgs = [misc.imresize(misc.imread(imgsDir+imgName+imgsType),size=[224,224]).reshape([1,224,224,3]) for imgName in imgsNames ]\n",
    "# imgFly = misc.imread('images/fly.jpg')\n",
    "# imgFly = misc.imresize(imgFly,size=[224,224])\n",
    "# imgCar = misc.imread('images/car.jpg')\n",
    "# imgCar = misc.imresize(imgCar,size=[224,224])\n",
    "# imgJet = misc.imread('images/jet.jpg')\n",
    "# imgJet = misc.imresize(imgJet,size=[224,224])\n",
    "\n",
    "#print(img.shape)    # (32, 32, 3)\n",
    "\n",
    "#img_tf = tf.Variable(img)\n",
    "#print(img_tf.get_shape().as_list())  # [32, 32, 3]\n",
    "\n",
    "# plt.imshow(imgFly)\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(imgCar)\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(imgJet)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "session.run(init_op)\n",
    "inputs = tf.placeholder(dtype=tf.float32,shape=(1,224,224,3))\n",
    "with tf.variable_scope('vgg_16', inputs, [1000]) as sc:\n",
    "        with slim.arg_scope([conv2d, fully_connected, max_pool2d]):\n",
    "            net = repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')\n",
    "            net = max_pool2d(net, [2, 2], scope='pool1')\n",
    "            net = repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')\n",
    "            net = max_pool2d(net, [2, 2], scope='pool2')\n",
    "            net = repeat(net, 3, slim.conv2d, 256, [3, 3], scope='conv3')\n",
    "            net = max_pool2d(net, [2, 2], scope='pool3')\n",
    "            net = repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv4')\n",
    "            net = max_pool2d(net, [2, 2], scope='pool4')\n",
    "            net = repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv5')\n",
    "            dir(net)\n",
    "            #net = max_pool2d(net, [2, 2], scope='pool5')\n",
    "            # Use conv2d instead of fully_connected layers.\n",
    "            #net = conv2d(net, 4096, [7, 7], padding='VALID', scope='fc6')\n",
    "            #net = conv2d(net, 4096, [1, 1], scope='fc7')\n",
    "            #net = conv2d(net, num_classes, [1, 1], activation_fn=None, normalizer_fn=None, scope='fc8')\n",
    "            for img in imgs:\n",
    "                probsOut = session.run([net],feed_dict={inputs:img})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
